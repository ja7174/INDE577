{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Use the keras module to import the necessary data \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Preparing and cleaning the data\n",
    "df = pd.read_csv(\"palmer_penguins.csv\")\n",
    "df = df.dropna()\n",
    "df = df.drop('Unnamed: 0', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Julia wants to dig her hands into neural networks. She has a bunch of data on all the penguins and she wants to see if a multi layer neural network can figure out what typre of penguin corresponds to a data point with a considerable feature vector.\n",
    "\n",
    "Given a set of feature vector of penguin characteris, can we now construct a model that will be able to guess what kind of penguin (Adelie, Gentoo or Chinstrap) just from the feature vector. Let's try to test it out.\n",
    "\n",
    "Before we do that we have to prepare our feature vector and our target vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Target Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can prepare our target vector in different kinds of ways. One in categorical form where we map each species to a number <br>\n",
    "Adelie ---> 0 <br>\n",
    "Chinstrap ---> 1 <br>\n",
    "Gentoo ---> 2 <br>\n",
    "<br>\n",
    "Another way to map the species is in vector form, for instance, <br>\n",
    "Adelie --> [1,0,0] <br>\n",
    "Chinstrap ---> [0,1,0] <br>\n",
    "Gentoo ---> [0,0,1] <br>\n",
    "\n",
    "We prepare the vectors in both form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type 1 Categorical\n",
    "cls = {\"Adelie\": 0,\n",
    "       \"Chinstrap\": 1,\n",
    "       \"Gentoo\": 2,}\n",
    "df[\"species_index\"] = df[\"species\"].apply(lambda x: cls[x])\n",
    "y_total = df['species_index'].values\n",
    "\n",
    "# Type 2 Vectorized\n",
    "onehot_train_y = []\n",
    "for y in y_total:   \n",
    "    temp_vec = np.zeros((3, 1))\n",
    "    temp_vec[y][0] = 1.0\n",
    "    onehot_train_y.append(temp_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Feature Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we prepare the feature vector. So, far we haven't used any of the qualitative variables in our models (like sex and island) both of which contain highly useful information (as we've seen previously). <br>\n",
    "\n",
    "We use one-hot-enchoding to convert the qualitative variable <b> island </b> to 3 boolean variables; isTorgerson, isBiscoe and isDream. Furthermore, since we've seen that the qualitative variable <b> sex </b> has only two unique values i.e. 'Male' and 'Female' we convert it a boolean called isFemale. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "# Data processing using one-hot-encoding\n",
    "df[\"isFemale\"] = np.where(df[\"sex\"]==\"Female\",1,0)\n",
    "df[\"isTorgersen\"] = np.where(df[\"island\"]==\"Torgersen\",1,0)\n",
    "df[\"isBiscoe\"] = np.where(df[\"island\"]==\"Biscoe\",1,0)\n",
    "df[\"isDream\"] = np.where(df[\"island\"]==\"Dream\",1,0)\n",
    "\n",
    "# Feature vector containing all the variables\n",
    "X =  df[[ \"bill_length_mm\",\"bill_depth_mm\",\"flipper_length_mm\",\"body_mass_g\",\n",
    "          \"isFemale\",\"isTorgersen\",\"isBiscoe\",\"isDream\"]].values \n",
    "\n",
    "# Scaling the feature vector so that all the variables are centered close to each other\n",
    "X[0:,0] = X[0:,0]/10\n",
    "X[0:,1] = X[0:,1]/10\n",
    "X[0:,2] = X[0:,2]/100\n",
    "X[0:,3] = X[0:,3]/1000\n",
    "np.shape(X[0])\n",
    "\n",
    "# Also create a flattened train of feature vectors\n",
    "flat_train_X = []\n",
    "for x in X:   \n",
    "    flat_train_X.append(x.flatten().reshape(8, 1))\n",
    "    \n",
    "print(np.shape(flat_train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y_total, test_size= 0.3, random_state =42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing a Mutli Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(8,)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(3)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Dense neuron with a RELU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8584\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8541\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8798\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8326\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8927\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8670\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8927\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8927\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.9013\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.9185\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.9270\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.9313\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.9056\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2806 - accuracy: 0.9227\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.9013\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2644 - accuracy: 0.9356\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.9485\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2586 - accuracy: 0.9528\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.9399\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.9227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa115b75d60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've reached about 93% accurace with just 20 epochs. Let's see how this model performs on the test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2034 - accuracy: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2033604383468628, 0.9700000286102295]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performs very well - almost 97% accuracy! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
